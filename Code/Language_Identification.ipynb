{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YHZvJ62jj5A9",
        "0eGRc-ycoXAH",
        "s-lSid77j9SM",
        "NHYonZsE6KLw",
        "TZN03VKgqSoK",
        "5oXStXg5sEq6"
      ],
      "authorship_tag": "ABX9TyNVccEkzahYTZzPkusu360L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsadiAhmad/Language-Identification/blob/main/Code/Language_Identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Import Libraries"
      ],
      "metadata": {
        "id": "YHZvJ62jj5A9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "uIMSTr5Nj2UF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "\n",
        "from collections import Counter\n",
        "from typing import Dict, Set, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Select Languages"
      ],
      "metadata": {
        "id": "0eGRc-ycoXAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   ara: Arabic\n",
        "2.   nld: Dutch\n",
        "3.   eng: English\n",
        "4.   ita: Italian\n",
        "5.   fra: French\n",
        "6.   deu: German\n",
        "7.   pes: Persian\n",
        "8.   rus: Russian\n",
        "9.   spa: Spanish\n",
        "10.  tur: Turkish"
      ],
      "metadata": {
        "id": "OAjGx055qQlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "languages = [\n",
        "    \"ara\",\n",
        "    \"nld\",\n",
        "    \"eng\",\n",
        "    \"ita\",\n",
        "    \"fra\",\n",
        "    \"deu\",\n",
        "    \"pes\",\n",
        "    \"rus\",\n",
        "    \"spa\",\n",
        "    \"tur\"\n",
        "]"
      ],
      "metadata": {
        "id": "xiycBjrUodx3"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Download Dataset"
      ],
      "metadata": {
        "id": "s-lSid77j9SM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p \"dataset-bz2\""
      ],
      "metadata": {
        "id": "0Fa8tFAKrPfs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "links = []\n",
        "for language in languages:\n",
        "    links.append(f\"https://downloads.tatoeba.org/exports/per_language/{language}/{language}_sentences.tsv.bz2\")"
      ],
      "metadata": {
        "id": "FvQxQzsIwC9E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for link in links:\n",
        "    !wget -P ./dataset-bz2/ {link}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM493eldqYtl",
        "outputId": "38f72f5d-de45-4cd4-c9e9-4a9dc1927a1a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-21 17:13:04--  https://downloads.tatoeba.org/exports/per_language/ara/ara_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 743296 (726K) [application/octet-stream]\n",
            "Saving to: ‘./dataset-bz2/ara_sentences.tsv.bz2’\n",
            "\n",
            "ara_sentences.tsv.b 100%[===================>] 725.88K   717KB/s    in 1.0s    \n",
            "\n",
            "2025-05-21 17:13:06 (717 KB/s) - ‘./dataset-bz2/ara_sentences.tsv.bz2’ saved [743296/743296]\n",
            "\n",
            "--2025-05-21 17:13:06--  https://downloads.tatoeba.org/exports/per_language/nld/nld_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2376235 (2.3M) [application/octet-stream]\n",
            "Saving to: ‘./dataset-bz2/nld_sentences.tsv.bz2’\n",
            "\n",
            "nld_sentences.tsv.b 100%[===================>]   2.27M  1.60MB/s    in 1.4s    \n",
            "\n",
            "2025-05-21 17:13:09 (1.60 MB/s) - ‘./dataset-bz2/nld_sentences.tsv.bz2’ saved [2376235/2376235]\n",
            "\n",
            "--2025-05-21 17:13:09--  https://downloads.tatoeba.org/exports/per_language/eng/eng_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23950305 (23M) [application/octet-stream]\n",
            "Saving to: ‘./dataset-bz2/eng_sentences.tsv.bz2’\n",
            "\n",
            "eng_sentences.tsv.b 100%[===================>]  22.84M  7.90MB/s    in 2.9s    \n",
            "\n",
            "2025-05-21 17:13:13 (7.90 MB/s) - ‘./dataset-bz2/eng_sentences.tsv.bz2’ saved [23950305/23950305]\n",
            "\n",
            "--2025-05-21 17:13:13--  https://downloads.tatoeba.org/exports/per_language/ita/ita_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8840373 (8.4M) [application/octet-stream]\n",
            "Saving to: ‘./dataset-bz2/ita_sentences.tsv.bz2’\n",
            "\n",
            "ita_sentences.tsv.b 100%[===================>]   8.43M  4.22MB/s    in 2.0s    \n",
            "\n",
            "2025-05-21 17:13:16 (4.22 MB/s) - ‘./dataset-bz2/ita_sentences.tsv.bz2’ saved [8840373/8840373]\n",
            "\n",
            "--2025-05-21 17:13:16--  https://downloads.tatoeba.org/exports/per_language/fra/fra_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8940058 (8.5M) [application/octet-stream]\n",
            "Saving to: ‘./dataset-bz2/fra_sentences.tsv.bz2’\n",
            "\n",
            "fra_sentences.tsv.b 100%[===================>]   8.53M  4.52MB/s    in 1.9s    \n",
            "\n",
            "2025-05-21 17:13:19 (4.52 MB/s) - ‘./dataset-bz2/fra_sentences.tsv.bz2’ saved [8940058/8940058]\n",
            "\n",
            "--2025-05-21 17:13:19--  https://downloads.tatoeba.org/exports/per_language/deu/deu_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11169254 (11M) [application/octet-stream]\n",
            "Saving to: ‘./dataset-bz2/deu_sentences.tsv.bz2’\n",
            "\n",
            "deu_sentences.tsv.b 100%[===================>]  10.65M  5.74MB/s    in 1.9s    \n",
            "\n",
            "2025-05-21 17:13:22 (5.74 MB/s) - ‘./dataset-bz2/deu_sentences.tsv.bz2’ saved [11169254/11169254]\n",
            "\n",
            "--2025-05-21 17:13:22--  https://downloads.tatoeba.org/exports/per_language/pes/pes_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 462974 (452K) [application/octet-stream]\n",
            "Saving to: ‘./dataset-bz2/pes_sentences.tsv.bz2’\n",
            "\n",
            "pes_sentences.tsv.b 100%[===================>] 452.12K   542KB/s    in 0.8s    \n",
            "\n",
            "2025-05-21 17:13:24 (542 KB/s) - ‘./dataset-bz2/pes_sentences.tsv.bz2’ saved [462974/462974]\n",
            "\n",
            "--2025-05-21 17:13:24--  https://downloads.tatoeba.org/exports/per_language/rus/rus_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14167814 (14M) [application/octet-stream]\n",
            "Saving to: ‘./dataset-bz2/rus_sentences.tsv.bz2’\n",
            "\n",
            "rus_sentences.tsv.b 100%[===================>]  13.51M  6.35MB/s    in 2.1s    \n",
            "\n",
            "2025-05-21 17:13:27 (6.35 MB/s) - ‘./dataset-bz2/rus_sentences.tsv.bz2’ saved [14167814/14167814]\n",
            "\n",
            "--2025-05-21 17:13:27--  https://downloads.tatoeba.org/exports/per_language/spa/spa_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5863408 (5.6M) [application/octet-stream]\n",
            "Saving to: ‘./dataset-bz2/spa_sentences.tsv.bz2’\n",
            "\n",
            "spa_sentences.tsv.b 100%[===================>]   5.59M  3.02MB/s    in 1.9s    \n",
            "\n",
            "2025-05-21 17:13:30 (3.02 MB/s) - ‘./dataset-bz2/spa_sentences.tsv.bz2’ saved [5863408/5863408]\n",
            "\n",
            "--2025-05-21 17:13:30--  https://downloads.tatoeba.org/exports/per_language/tur/tur_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8434760 (8.0M) [application/octet-stream]\n",
            "Saving to: ‘./dataset-bz2/tur_sentences.tsv.bz2’\n",
            "\n",
            "tur_sentences.tsv.b 100%[===================>]   8.04M  4.29MB/s    in 1.9s    \n",
            "\n",
            "2025-05-21 17:13:33 (4.29 MB/s) - ‘./dataset-bz2/tur_sentences.tsv.bz2’ saved [8434760/8434760]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Unzip Dataset"
      ],
      "metadata": {
        "id": "I_oQTuk0w6aB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf /content/dataset-btsv/"
      ],
      "metadata": {
        "id": "xnDeq5hZ5W2J"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p \"dataset-tsv\""
      ],
      "metadata": {
        "id": "FA5DH4nxsyrS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in os.listdir(\"./dataset-bz2\"):\n",
        "    input_path = os.path.join(\"dataset-bz2\", filename)\n",
        "    output_path = os.path.join(\"dataset-tsv\", filename.replace(\".bz2\", \"\"))\n",
        "    !bzip2 -dkc {input_path} > {output_path}"
      ],
      "metadata": {
        "id": "__g_bE1ZyX6H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Convert TSV files to TXT files"
      ],
      "metadata": {
        "id": "NHYonZsE6KLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p \"dataset-txt\""
      ],
      "metadata": {
        "id": "3pJ8sano6PU6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in os.listdir(\"./dataset-tsv\"):\n",
        "    input_path = os.path.join(\"dataset-tsv\", filename)\n",
        "    output_path = os.path.join(\"dataset-txt\", filename.replace(\".tsv\", \".txt\"))\n",
        "    !cp {input_path} {output_path}"
      ],
      "metadata": {
        "id": "IuJ9bpKW6gfn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Convert text files into Polars frame"
      ],
      "metadata": {
        "id": "B3_Bev-lVG1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_file_to_data(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    data = []\n",
        "    for line in lines:\n",
        "        parts = line.strip().split('\\t')\n",
        "        if len(parts) >= 3:\n",
        "            language = parts[1]\n",
        "            text = parts[2]\n",
        "            data.append((language, text))\n",
        "    return data"
      ],
      "metadata": {
        "id": "GEk2ObxiiJ62"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pl.DataFrame(\n",
        "    {\n",
        "        \"language\": pl.Series(dtype=pl.Utf8),\n",
        "        \"text\": pl.Series(dtype=pl.Utf8)\n",
        "    }\n",
        ").with_row_index(name=\"index\")"
      ],
      "metadata": {
        "id": "j3Rzxgy6VNqE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in os.listdir(\"./dataset-txt\"):\n",
        "    input_path = os.path.join(\"dataset-txt\", filename)\n",
        "    file_data = convert_file_to_data(input_path)\n",
        "\n",
        "    temp_dataframe = pl.DataFrame(\n",
        "        {\n",
        "            \"language\": [item[0] for item in file_data],\n",
        "            \"text\": [item[1] for item in file_data]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    data = pl.concat([data, temp_dataframe], how=\"diagonal\")"
      ],
      "metadata": {
        "id": "0q3ChwPdiSEI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if \"index\" in data.columns:\n",
        "    data = data.drop(\"index\")\n",
        "data = data.with_row_index(name=\"index\", offset=0)"
      ],
      "metadata": {
        "id": "-FkEOGnFoSUJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "5gq-PIlbm9vN",
        "outputId": "7167fa22-1cd5-4a7a-c12b-4a88f54a8476"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (10, 3)\n",
              "┌───────┬──────────┬─────────────────────────────────┐\n",
              "│ index ┆ language ┆ text                            │\n",
              "│ ---   ┆ ---      ┆ ---                             │\n",
              "│ u32   ┆ str      ┆ str                             │\n",
              "╞═══════╪══════════╪═════════════════════════════════╡\n",
              "│ 0     ┆ spa      ┆ ¡Intentemos algo!               │\n",
              "│ 1     ┆ spa      ┆ Tengo que irme a dormir.        │\n",
              "│ 2     ┆ spa      ┆ ¿Qué estás haciendo?            │\n",
              "│ 3     ┆ spa      ┆ ¿Qué es eso?                    │\n",
              "│ 4     ┆ spa      ┆ ¡Hoy es 18 de junio y es el cu… │\n",
              "│ 5     ┆ spa      ┆ ¡Feliz cumpleaños, Muiriel!     │\n",
              "│ 6     ┆ spa      ┆ Ahora, Muiriel tiene 20 años.   │\n",
              "│ 7     ┆ spa      ┆ La contraseña es \"Muiriel\".     │\n",
              "│ 8     ┆ spa      ┆ Volveré pronto.                 │\n",
              "│ 9     ┆ spa      ┆ No tengo palabras.              │\n",
              "└───────┴──────────┴─────────────────────────────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (10, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>language</th><th>text</th></tr><tr><td>u32</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>&quot;spa&quot;</td><td>&quot;¡Intentemos algo!&quot;</td></tr><tr><td>1</td><td>&quot;spa&quot;</td><td>&quot;Tengo que irme a dormir.&quot;</td></tr><tr><td>2</td><td>&quot;spa&quot;</td><td>&quot;¿Qué estás haciendo?&quot;</td></tr><tr><td>3</td><td>&quot;spa&quot;</td><td>&quot;¿Qué es eso?&quot;</td></tr><tr><td>4</td><td>&quot;spa&quot;</td><td>&quot;¡Hoy es 18 de junio y es el cu…</td></tr><tr><td>5</td><td>&quot;spa&quot;</td><td>&quot;¡Feliz cumpleaños, Muiriel!&quot;</td></tr><tr><td>6</td><td>&quot;spa&quot;</td><td>&quot;Ahora, Muiriel tiene 20 años.&quot;</td></tr><tr><td>7</td><td>&quot;spa&quot;</td><td>&quot;La contraseña es &quot;Muiriel&quot;.&quot;</td></tr><tr><td>8</td><td>&quot;spa&quot;</td><td>&quot;Volveré pronto.&quot;</td></tr><tr><td>9</td><td>&quot;spa&quot;</td><td>&quot;No tengo palabras.&quot;</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.height"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKpEYAVHqHF5",
        "outputId": "6d0e2441-79a4-4c61-cc89-f5d9f954d6db"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6854075"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Preprocess"
      ],
      "metadata": {
        "id": "TZN03VKgqSoK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean garbage characters"
      ],
      "metadata": {
        "id": "5oXStXg5sEq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(dataframe):\n",
        "    chars_to_replace = [\"！\", \"？\", \"｡\", \"。\", \"＂\", \"＃\", \"＄\", \"％\", \"＆\", \"＇\",\n",
        "                        \"（\", \"）\", \"＊\", \"＋\", \"，\", \"－\", \"／\", \"：\", \"；\", \"＜\",\n",
        "                        \"＝\", \"＞\", \"＠\", \"［\", \"＼\", \"］\", \"＾\", \"＿\", \"｀\", \"｛\",\n",
        "                        \"｜\", \"｝\", \"～\", \"｟\", \"｠\", \"｢\", \"｣\", \"､\", \"、\", \"〃\",\n",
        "                        \"》\", \"「\", \"」\", \"『\", \"』\", \"【\", \"】\", \"〔\", \"〕\", \"〖\",\n",
        "                        \"〗\", \"〘\", \"〙\", \"〚\", \"〛\", \"〜\", \"〝\", \"〞\", \"〟\", \"〰\",\n",
        "                        \"〾\", \"〿\", \"–\", \"—\", \"‘\", \"’\", \"‛\", \"“\", \"”\", \"„\", \"‟\",\n",
        "                        \"…\", \"‧\", \"﹏\", \".\", \",\", \"(\", \")\", \"{\", \"}\", \"[\", \"]\",\n",
        "                        \"!\", \"@\", \"#\", \"$\", \"%\", \"^\", \"&\", \"*\", \"?\", \"_\", \"-\",\n",
        "                        \"+\", \"=\", \"/\", \"`\", \"~\", \"'\", \";\", \":\", \"]\", \"¡\", \"\\\"\",\n",
        "                        \"<\", \">\", \"€\", \"𝑐\", \"π\", \"№\", \"―\", \"̀\", \"́\", \"×\", \"œ\", \"Œ\",\n",
        "                        \"ŭ\", \"ɛ\", \"ɣ\", \"а\", \"ḍ\", \"ḥ\", \"ṛ\", \"ẓ\", \"መ\", \"ሀ\", \"ለ\",\n",
        "                        \"ል\", \"ም\", \"ር\", \"ሰ\", \"በ\", \"ብ\", \"ት\", \"ኒ\", \"ን\", \"አ\", \"እ\",\n",
        "                        \"ካ\", \"ክ\", \"ይ\", \"።\", \"ٱ\", \"ٰ\", \"ْ\", \"ٍ\", \"«\", \"»\", \"°\", \"¹\",\n",
        "                        \"²\", \"³\", \"´\", \"§\", \"½\", \"√\", \"−\", \"ℝ\", \"𝑘\", \"𝑥\", \"₄\",\n",
        "                        \"₂\", \"⁰\", \"›\", \"‹\", \"′\", \"¿\", \"º\", \"ま\", \"£\", \"¥\", \"か\",\n",
        "                        \"の\", \"₺\", \"٪\", \"؟\", \"؛\", \"ѣ\" ]\n",
        "    pattern = \"[\" + re.escape(\"\".join(chars_to_replace)) + \"]\"\n",
        "\n",
        "    dataframe = dataframe.with_columns(\n",
        "        pl.col(\"text\")\n",
        "        .str.replace_all(pattern, \" \")  # Remove special characters\n",
        "        .str.replace_all(r\"\\d\", \" \")    # Remove digits\n",
        "        .str.replace_all(r\"\\s+\", \" \")   # Replace multiple whitespace with single space\n",
        "        .str.strip_chars()              # Remove leading/trailing whitespace\n",
        "    )\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "HkPUrclRQV0p"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data = clean_text(data)"
      ],
      "metadata": {
        "id": "zbqxpQSJQelk"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Split Train set and Validation set"
      ],
      "metadata": {
        "id": "Lpbr4JIitkN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_validation_split_by_language(data, samples_per_language=100):\n",
        "    validation_set = (\n",
        "        data\n",
        "        .group_by(\"language\")\n",
        "        .map_groups(lambda group:\n",
        "            group.sample(n=min(samples_per_language, len(group))))\n",
        "    )\n",
        "\n",
        "    training_set = data.join(\n",
        "        validation_set.select(\"index\"),\n",
        "        on=\"index\",\n",
        "        how=\"anti\"\n",
        "    )\n",
        "\n",
        "    if \"index\" in training_set.columns:\n",
        "        training_set = training_set.drop(\"index\")\n",
        "    training_set = training_set.with_row_index(name=\"index\", offset=0)\n",
        "\n",
        "    if \"index\" in validation_set.columns:\n",
        "        validation_set = validation_set.drop(\"index\")\n",
        "    validation_set = validation_set.with_row_index(name=\"index\", offset=0)\n",
        "\n",
        "    return training_set, validation_set"
      ],
      "metadata": {
        "id": "4hf8DHAN8EDk"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "training_set, validation_set = train_validation_split_by_language(cleaned_data)"
      ],
      "metadata": {
        "id": "BN7qXkDO8aRu"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training data shape: {training_set.shape}\")\n",
        "print(f\"Validation data shape: {validation_set.shape}\")\n",
        "print(\"\\nValidation samples per language:\")\n",
        "print(validation_set[\"language\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWHE0PhytzCG",
        "outputId": "7e237e6a-788d-449f-fd33-aa503e76dd3c"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (6853075, 3)\n",
            "Validation data shape: (1000, 3)\n",
            "\n",
            "Validation samples per language:\n",
            "shape: (10, 2)\n",
            "┌──────────┬───────┐\n",
            "│ language ┆ count │\n",
            "│ ---      ┆ ---   │\n",
            "│ str      ┆ u32   │\n",
            "╞══════════╪═══════╡\n",
            "│ eng      ┆ 100   │\n",
            "│ ita      ┆ 100   │\n",
            "│ pes      ┆ 100   │\n",
            "│ deu      ┆ 100   │\n",
            "│ tur      ┆ 100   │\n",
            "│ spa      ┆ 100   │\n",
            "│ ara      ┆ 100   │\n",
            "│ fra      ┆ 100   │\n",
            "│ nld      ┆ 100   │\n",
            "│ rus      ┆ 100   │\n",
            "└──────────┴───────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Filter all Language chracters"
      ],
      "metadata": {
        "id": "JpOPG0bQ8rs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_language_chars_dictionary(\n",
        "    data: pl.DataFrame,\n",
        "    cutoff_thresholds: Dict[str, int] = None,\n",
        "    default_cutoff: int = 10\n",
        ") -> Tuple[Dict[str, Set[str]], Dict[str, Dict[str, int]]]:\n",
        "\n",
        "    languages = data[\"language\"].unique().to_list()\n",
        "    char_frequencies = {lang: Counter() for lang in languages}\n",
        "    language_chars = {lang: set() for lang in languages}\n",
        "\n",
        "    for language, text in data.select([\"language\", \"text\"]).iter_rows():\n",
        "        char_frequencies[language].update(text)\n",
        "\n",
        "    for lang in languages:\n",
        "        threshold = cutoff_thresholds.get(lang, default_cutoff)\n",
        "        language_chars[lang] = {\n",
        "            char for char, count in char_frequencies[lang].items()\n",
        "            if count >= threshold\n",
        "        }\n",
        "\n",
        "    return language_chars, char_frequencies"
      ],
      "metadata": {
        "id": "kOTXUiRVBg5r"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cutoff_thresholds = {\n",
        "    \"ara\": 100,\n",
        "    \"nld\": 100,\n",
        "    \"eng\": 100,\n",
        "    \"ita\": 100,\n",
        "    \"fra\": 100,\n",
        "    \"deu\": 100,\n",
        "    \"pes\": 100,\n",
        "    \"rus\": 100,\n",
        "    \"spa\": 100,\n",
        "    \"tur\": 100\n",
        "}\n",
        "\n",
        "language_chars, char_frequencies = create_language_chars_dictionary(training_set, cutoff_thresholds=cutoff_thresholds, default_cutoff=100)\n",
        "\n",
        "for lang, chars in language_chars.items():\n",
        "    threshold = cutoff_thresholds.get(lang, 100)\n",
        "    print(f\"\\nLanguage: {lang} (cutoff: {threshold})\")\n",
        "    print(f\"Total unique chars: {len(char_frequencies[lang])}\")\n",
        "    print(f\"Filtered chars count: {len(chars)}\")\n",
        "    print(\"Sample frequent chars:\", sorted(list(chars))[:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zG03PeWCCbm",
        "outputId": "7ccbc761-12f3-406f-b2f5-eb7ee6729dae"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Language: deu (cutoff: 100)\n",
            "Total unique chars: 335\n",
            "Filtered chars count: 64\n",
            "Sample frequent chars: [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xad', 'Ä', 'Ö', 'Ü', 'ß', 'ä', 'é', 'ö', 'ü', 'ō', '‚']\n",
            "\n",
            "Language: ara (cutoff: 100)\n",
            "Total unique chars: 183\n",
            "Filtered chars count: 45\n",
            "Sample frequent chars: [' ', '،', 'ء', 'آ', 'أ', 'ؤ', 'إ', 'ئ', 'ا', 'ب', 'ة', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ي', 'ً', 'ٌ', 'َ', 'ُ', 'ِ', 'ّ', 'ی']\n",
            "\n",
            "Language: tur (cutoff: 100)\n",
            "Total unique chars: 180\n",
            "Filtered chars count: 65\n",
            "Sample frequent chars: [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Ç', 'Ö', 'Ü', 'â', 'ç', 'î', 'ö', 'û', 'ü', 'ğ', 'İ', 'ı', 'Ş', 'ş', '\\u200b']\n",
            "\n",
            "Language: pes (cutoff: 100)\n",
            "Total unique chars: 126\n",
            "Filtered chars count: 45\n",
            "Sample frequent chars: [' ', '،', 'ء', 'آ', 'أ', 'ؤ', 'ئ', 'ا', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ي', 'ً', 'ِ', 'ٔ', 'پ', 'چ', 'ژ', 'ک', 'گ', 'ی', '\\u200c']\n",
            "\n",
            "Language: rus (cutoff: 100)\n",
            "Total unique chars: 232\n",
            "Filtered chars count: 98\n",
            "Sample frequent chars: [' ', 'A', 'B', 'C', 'D', 'F', 'I', 'L', 'M', 'P', 'S', 'T', 'V', 'W', 'X', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'w', 'x', 'y', 'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Э', 'Ю', 'Я', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё', '\\u200b']\n",
            "\n",
            "Language: fra (cutoff: 100)\n",
            "Total unique chars: 221\n",
            "Filtered chars count: 70\n",
            "Sample frequent chars: [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'À', 'Ç', 'É', 'Ê', 'Ô', 'à', 'â', 'ç', 'è', 'é', 'ê', 'ë', 'î', 'ï', 'ô', 'ù', 'û']\n",
            "\n",
            "Language: nld (cutoff: 100)\n",
            "Total unique chars: 140\n",
            "Filtered chars count: 57\n",
            "Sample frequent chars: [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'è', 'é', 'ë', 'ï', 'ü', '\\u200b']\n",
            "\n",
            "Language: eng (cutoff: 100)\n",
            "Total unique chars: 415\n",
            "Filtered chars count: 56\n",
            "Sample frequent chars: [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'á', 'é', 'í']\n",
            "\n",
            "Language: spa (cutoff: 100)\n",
            "Total unique chars: 187\n",
            "Filtered chars count: 63\n",
            "Sample frequent chars: [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Á', 'É', 'Ú', 'á', 'é', 'í', 'ñ', 'ó', 'ú', 'ü']\n",
            "\n",
            "Language: ita (cutoff: 100)\n",
            "Total unique chars: 159\n",
            "Filtered chars count: 60\n",
            "Sample frequent chars: [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'È', 'à', 'è', 'é', 'ì', 'ò', 'ù']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 10: Predict Language by chars"
      ],
      "metadata": {
        "id": "1wBGxrIpNDf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_language_by_chars(validation_set: pl.DataFrame, language_chars: dict[str, set[str]]) -> pl.DataFrame:\n",
        "    lang_char_sets = {lang: set(chars) for lang, chars in language_chars.items()}\n",
        "    languages = list(lang_char_sets.keys())\n",
        "\n",
        "    text_chars_list = validation_set[\"text\"].to_list()\n",
        "    predictions = []\n",
        "\n",
        "    for text in text_chars_list:\n",
        "        text_chars = set(text)\n",
        "        best_lang = max(\n",
        "            languages,\n",
        "            key=lambda lang: len(text_chars & lang_char_sets[lang])\n",
        "        )\n",
        "        predictions.append(best_lang)\n",
        "\n",
        "    return validation_set.with_columns(\n",
        "        predicted_language=pl.Series(predictions)\n",
        "    )"
      ],
      "metadata": {
        "id": "nk9ec2TANE9h"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_set = predict_language_by_chars(validation_set, language_chars)"
      ],
      "metadata": {
        "id": "368hoUIYVE4Y"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_set.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "rf2qeYuZVVjp",
        "outputId": "a63ce8ac-a3b4-4789-b4cb-d9db6bc22628"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (10, 4)\n",
              "┌───────┬──────────┬─────────────────────────────────┬────────────────────┐\n",
              "│ index ┆ language ┆ text                            ┆ predicted_language │\n",
              "│ ---   ┆ ---      ┆ ---                             ┆ ---                │\n",
              "│ u32   ┆ str      ┆ str                             ┆ str                │\n",
              "╞═══════╪══════════╪═════════════════════════════════╪════════════════════╡\n",
              "│ 0     ┆ tur      ┆ O kadar da komik değildi        ┆ tur                │\n",
              "│ 1     ┆ tur      ┆ Avustralya da konuşulan dil İn… ┆ tur                │\n",
              "│ 2     ┆ tur      ┆ Bu fotoğrafı görünce ailemi dü… ┆ tur                │\n",
              "│ 3     ┆ tur      ┆ Burada İspanyolca konuşulur     ┆ tur                │\n",
              "│ 4     ┆ tur      ┆ Dinsiz piskoposun yorumuyla al… ┆ deu                │\n",
              "│ 5     ┆ tur      ┆ Üye misiniz                     ┆ deu                │\n",
              "│ 6     ┆ tur      ┆ Yayan gittim                    ┆ deu                │\n",
              "│ 7     ┆ tur      ┆ Bilim hakkında daha fazla bilm… ┆ tur                │\n",
              "│ 8     ┆ tur      ┆ Altın gümüşten daha ağırdır     ┆ tur                │\n",
              "│ 9     ┆ tur      ┆ Tom Mary ile konuşuyor          ┆ tur                │\n",
              "└───────┴──────────┴─────────────────────────────────┴────────────────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (10, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>language</th><th>text</th><th>predicted_language</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>&quot;tur&quot;</td><td>&quot;O kadar da komik değildi&quot;</td><td>&quot;tur&quot;</td></tr><tr><td>1</td><td>&quot;tur&quot;</td><td>&quot;Avustralya da konuşulan dil İn…</td><td>&quot;tur&quot;</td></tr><tr><td>2</td><td>&quot;tur&quot;</td><td>&quot;Bu fotoğrafı görünce ailemi dü…</td><td>&quot;tur&quot;</td></tr><tr><td>3</td><td>&quot;tur&quot;</td><td>&quot;Burada İspanyolca konuşulur&quot;</td><td>&quot;tur&quot;</td></tr><tr><td>4</td><td>&quot;tur&quot;</td><td>&quot;Dinsiz piskoposun yorumuyla al…</td><td>&quot;deu&quot;</td></tr><tr><td>5</td><td>&quot;tur&quot;</td><td>&quot;Üye misiniz&quot;</td><td>&quot;deu&quot;</td></tr><tr><td>6</td><td>&quot;tur&quot;</td><td>&quot;Yayan gittim&quot;</td><td>&quot;deu&quot;</td></tr><tr><td>7</td><td>&quot;tur&quot;</td><td>&quot;Bilim hakkında daha fazla bilm…</td><td>&quot;tur&quot;</td></tr><tr><td>8</td><td>&quot;tur&quot;</td><td>&quot;Altın gümüşten daha ağırdır&quot;</td><td>&quot;tur&quot;</td></tr><tr><td>9</td><td>&quot;tur&quot;</td><td>&quot;Tom Mary ile konuşuyor&quot;</td><td>&quot;tur&quot;</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 11: Calculate Detailed Accuracy"
      ],
      "metadata": {
        "id": "1dTXb154WUOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_detailed_accuracy(df: pl.DataFrame) -> dict:\n",
        "    confusion_counts = (\n",
        "        df\n",
        "        .group_by(\"language\", \"predicted_language\")\n",
        "        .agg(pl.len().alias(\"n\"))\n",
        "        .sort(\"language\", \"predicted_language\")\n",
        "    )\n",
        "\n",
        "    class_acc = (\n",
        "        df\n",
        "        .group_by(\"language\")\n",
        "        .agg(\n",
        "            (pl.col(\"language\") == pl.col(\"predicted_language\"))\n",
        "            .mean()\n",
        "            .alias(\"accuracy\")\n",
        "        )\n",
        "        .sort(\"language\")\n",
        "    )\n",
        "\n",
        "    class_acc_dict = {\n",
        "        row[\"language\"]: row[\"accuracy\"]\n",
        "        for row in class_acc.iter_rows(named=True)\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        \"overall_accuracy\": (df[\"language\"] == df[\"predicted_language\"]).mean(),\n",
        "        \"class_accuracy\": class_acc_dict,\n",
        "        \"confusion_counts\": confusion_counts\n",
        "    }"
      ],
      "metadata": {
        "id": "Mj2qm_JqcflA"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = calculate_detailed_accuracy(validation_set)"
      ],
      "metadata": {
        "id": "sQT9C7pqeWLN"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Overall Accuracy: {metrics['overall_accuracy']:.2%}\")\n",
        "print(\"\\nPer-Class Accuracy:\")\n",
        "for lang, acc in metrics[\"class_accuracy\"].items():\n",
        "    print(f\"{lang}: {acc:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVseXjdieVn9",
        "outputId": "eeea457d-b49b-4458-b7ff-31cd3131c5b1"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy: 52.50%\n",
            "\n",
            "Per-Class Accuracy:\n",
            "ara: 100.00%\n",
            "deu: 100.00%\n",
            "eng: 0.00%\n",
            "fra: 35.00%\n",
            "ita: 3.00%\n",
            "nld: 0.00%\n",
            "pes: 81.00%\n",
            "rus: 100.00%\n",
            "spa: 23.00%\n",
            "tur: 83.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 12:"
      ],
      "metadata": {
        "id": "Z-kXk9eaei1h"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MND_iwVremdH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}