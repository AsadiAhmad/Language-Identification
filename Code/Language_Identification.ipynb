{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YHZvJ62jj5A9",
        "0eGRc-ycoXAH",
        "s-lSid77j9SM",
        "NHYonZsE6KLw",
        "TZN03VKgqSoK",
        "5oXStXg5sEq6"
      ],
      "authorship_tag": "ABX9TyNVccEkzahYTZzPkusu360L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsadiAhmad/Language-Identification/blob/main/Code/Language_Identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Import Libraries"
      ],
      "metadata": {
        "id": "YHZvJ62jj5A9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "uIMSTr5Nj2UF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "\n",
        "from collections import Counter\n",
        "from typing import Dict, Set, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Select Languages"
      ],
      "metadata": {
        "id": "0eGRc-ycoXAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   ara: Arabic\n",
        "2.   nld: Dutch\n",
        "3.   eng: English\n",
        "4.   ita: Italian\n",
        "5.   fra: French\n",
        "6.   deu: German\n",
        "7.   pes: Persian\n",
        "8.   rus: Russian\n",
        "9.   spa: Spanish\n",
        "10.  tur: Turkish"
      ],
      "metadata": {
        "id": "OAjGx055qQlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "languages = [\n",
        "    \"ara\",\n",
        "    \"nld\",\n",
        "    \"eng\",\n",
        "    \"ita\",\n",
        "    \"fra\",\n",
        "    \"deu\",\n",
        "    \"pes\",\n",
        "    \"rus\",\n",
        "    \"spa\",\n",
        "    \"tur\"\n",
        "]"
      ],
      "metadata": {
        "id": "xiycBjrUodx3"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Download Dataset"
      ],
      "metadata": {
        "id": "s-lSid77j9SM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p \"dataset-bz2\""
      ],
      "metadata": {
        "id": "0Fa8tFAKrPfs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "links = []\n",
        "for language in languages:\n",
        "    links.append(f\"https://downloads.tatoeba.org/exports/per_language/{language}/{language}_sentences.tsv.bz2\")"
      ],
      "metadata": {
        "id": "FvQxQzsIwC9E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for link in links:\n",
        "    !wget -P ./dataset-bz2/ {link}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM493eldqYtl",
        "outputId": "38f72f5d-de45-4cd4-c9e9-4a9dc1927a1a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-21 17:13:04--  https://downloads.tatoeba.org/exports/per_language/ara/ara_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 743296 (726K) [application/octet-stream]\n",
            "Saving to: â€˜./dataset-bz2/ara_sentences.tsv.bz2â€™\n",
            "\n",
            "ara_sentences.tsv.b 100%[===================>] 725.88K   717KB/s    in 1.0s    \n",
            "\n",
            "2025-05-21 17:13:06 (717 KB/s) - â€˜./dataset-bz2/ara_sentences.tsv.bz2â€™ saved [743296/743296]\n",
            "\n",
            "--2025-05-21 17:13:06--  https://downloads.tatoeba.org/exports/per_language/nld/nld_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2376235 (2.3M) [application/octet-stream]\n",
            "Saving to: â€˜./dataset-bz2/nld_sentences.tsv.bz2â€™\n",
            "\n",
            "nld_sentences.tsv.b 100%[===================>]   2.27M  1.60MB/s    in 1.4s    \n",
            "\n",
            "2025-05-21 17:13:09 (1.60 MB/s) - â€˜./dataset-bz2/nld_sentences.tsv.bz2â€™ saved [2376235/2376235]\n",
            "\n",
            "--2025-05-21 17:13:09--  https://downloads.tatoeba.org/exports/per_language/eng/eng_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23950305 (23M) [application/octet-stream]\n",
            "Saving to: â€˜./dataset-bz2/eng_sentences.tsv.bz2â€™\n",
            "\n",
            "eng_sentences.tsv.b 100%[===================>]  22.84M  7.90MB/s    in 2.9s    \n",
            "\n",
            "2025-05-21 17:13:13 (7.90 MB/s) - â€˜./dataset-bz2/eng_sentences.tsv.bz2â€™ saved [23950305/23950305]\n",
            "\n",
            "--2025-05-21 17:13:13--  https://downloads.tatoeba.org/exports/per_language/ita/ita_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8840373 (8.4M) [application/octet-stream]\n",
            "Saving to: â€˜./dataset-bz2/ita_sentences.tsv.bz2â€™\n",
            "\n",
            "ita_sentences.tsv.b 100%[===================>]   8.43M  4.22MB/s    in 2.0s    \n",
            "\n",
            "2025-05-21 17:13:16 (4.22 MB/s) - â€˜./dataset-bz2/ita_sentences.tsv.bz2â€™ saved [8840373/8840373]\n",
            "\n",
            "--2025-05-21 17:13:16--  https://downloads.tatoeba.org/exports/per_language/fra/fra_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8940058 (8.5M) [application/octet-stream]\n",
            "Saving to: â€˜./dataset-bz2/fra_sentences.tsv.bz2â€™\n",
            "\n",
            "fra_sentences.tsv.b 100%[===================>]   8.53M  4.52MB/s    in 1.9s    \n",
            "\n",
            "2025-05-21 17:13:19 (4.52 MB/s) - â€˜./dataset-bz2/fra_sentences.tsv.bz2â€™ saved [8940058/8940058]\n",
            "\n",
            "--2025-05-21 17:13:19--  https://downloads.tatoeba.org/exports/per_language/deu/deu_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11169254 (11M) [application/octet-stream]\n",
            "Saving to: â€˜./dataset-bz2/deu_sentences.tsv.bz2â€™\n",
            "\n",
            "deu_sentences.tsv.b 100%[===================>]  10.65M  5.74MB/s    in 1.9s    \n",
            "\n",
            "2025-05-21 17:13:22 (5.74 MB/s) - â€˜./dataset-bz2/deu_sentences.tsv.bz2â€™ saved [11169254/11169254]\n",
            "\n",
            "--2025-05-21 17:13:22--  https://downloads.tatoeba.org/exports/per_language/pes/pes_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 462974 (452K) [application/octet-stream]\n",
            "Saving to: â€˜./dataset-bz2/pes_sentences.tsv.bz2â€™\n",
            "\n",
            "pes_sentences.tsv.b 100%[===================>] 452.12K   542KB/s    in 0.8s    \n",
            "\n",
            "2025-05-21 17:13:24 (542 KB/s) - â€˜./dataset-bz2/pes_sentences.tsv.bz2â€™ saved [462974/462974]\n",
            "\n",
            "--2025-05-21 17:13:24--  https://downloads.tatoeba.org/exports/per_language/rus/rus_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14167814 (14M) [application/octet-stream]\n",
            "Saving to: â€˜./dataset-bz2/rus_sentences.tsv.bz2â€™\n",
            "\n",
            "rus_sentences.tsv.b 100%[===================>]  13.51M  6.35MB/s    in 2.1s    \n",
            "\n",
            "2025-05-21 17:13:27 (6.35 MB/s) - â€˜./dataset-bz2/rus_sentences.tsv.bz2â€™ saved [14167814/14167814]\n",
            "\n",
            "--2025-05-21 17:13:27--  https://downloads.tatoeba.org/exports/per_language/spa/spa_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5863408 (5.6M) [application/octet-stream]\n",
            "Saving to: â€˜./dataset-bz2/spa_sentences.tsv.bz2â€™\n",
            "\n",
            "spa_sentences.tsv.b 100%[===================>]   5.59M  3.02MB/s    in 1.9s    \n",
            "\n",
            "2025-05-21 17:13:30 (3.02 MB/s) - â€˜./dataset-bz2/spa_sentences.tsv.bz2â€™ saved [5863408/5863408]\n",
            "\n",
            "--2025-05-21 17:13:30--  https://downloads.tatoeba.org/exports/per_language/tur/tur_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8434760 (8.0M) [application/octet-stream]\n",
            "Saving to: â€˜./dataset-bz2/tur_sentences.tsv.bz2â€™\n",
            "\n",
            "tur_sentences.tsv.b 100%[===================>]   8.04M  4.29MB/s    in 1.9s    \n",
            "\n",
            "2025-05-21 17:13:33 (4.29 MB/s) - â€˜./dataset-bz2/tur_sentences.tsv.bz2â€™ saved [8434760/8434760]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Unzip Dataset"
      ],
      "metadata": {
        "id": "I_oQTuk0w6aB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf /content/dataset-btsv/"
      ],
      "metadata": {
        "id": "xnDeq5hZ5W2J"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p \"dataset-tsv\""
      ],
      "metadata": {
        "id": "FA5DH4nxsyrS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in os.listdir(\"./dataset-bz2\"):\n",
        "    input_path = os.path.join(\"dataset-bz2\", filename)\n",
        "    output_path = os.path.join(\"dataset-tsv\", filename.replace(\".bz2\", \"\"))\n",
        "    !bzip2 -dkc {input_path} > {output_path}"
      ],
      "metadata": {
        "id": "__g_bE1ZyX6H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Convert TSV files to TXT files"
      ],
      "metadata": {
        "id": "NHYonZsE6KLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p \"dataset-txt\""
      ],
      "metadata": {
        "id": "3pJ8sano6PU6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in os.listdir(\"./dataset-tsv\"):\n",
        "    input_path = os.path.join(\"dataset-tsv\", filename)\n",
        "    output_path = os.path.join(\"dataset-txt\", filename.replace(\".tsv\", \".txt\"))\n",
        "    !cp {input_path} {output_path}"
      ],
      "metadata": {
        "id": "IuJ9bpKW6gfn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Convert text files into Polars frame"
      ],
      "metadata": {
        "id": "B3_Bev-lVG1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_file_to_data(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    data = []\n",
        "    for line in lines:\n",
        "        parts = line.strip().split('\\t')\n",
        "        if len(parts) >= 3:\n",
        "            language = parts[1]\n",
        "            text = parts[2]\n",
        "            data.append((language, text))\n",
        "    return data"
      ],
      "metadata": {
        "id": "GEk2ObxiiJ62"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pl.DataFrame(\n",
        "    {\n",
        "        \"language\": pl.Series(dtype=pl.Utf8),\n",
        "        \"text\": pl.Series(dtype=pl.Utf8)\n",
        "    }\n",
        ").with_row_index(name=\"index\")"
      ],
      "metadata": {
        "id": "j3Rzxgy6VNqE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in os.listdir(\"./dataset-txt\"):\n",
        "    input_path = os.path.join(\"dataset-txt\", filename)\n",
        "    file_data = convert_file_to_data(input_path)\n",
        "\n",
        "    temp_dataframe = pl.DataFrame(\n",
        "        {\n",
        "            \"language\": [item[0] for item in file_data],\n",
        "            \"text\": [item[1] for item in file_data]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    data = pl.concat([data, temp_dataframe], how=\"diagonal\")"
      ],
      "metadata": {
        "id": "0q3ChwPdiSEI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if \"index\" in data.columns:\n",
        "    data = data.drop(\"index\")\n",
        "data = data.with_row_index(name=\"index\", offset=0)"
      ],
      "metadata": {
        "id": "-FkEOGnFoSUJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "5gq-PIlbm9vN",
        "outputId": "7167fa22-1cd5-4a7a-c12b-4a88f54a8476"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (10, 3)\n",
              "â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
              "â”‚ index â”† language â”† text                            â”‚\n",
              "â”‚ ---   â”† ---      â”† ---                             â”‚\n",
              "â”‚ u32   â”† str      â”† str                             â”‚\n",
              "â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
              "â”‚ 0     â”† spa      â”† Â¡Intentemos algo!               â”‚\n",
              "â”‚ 1     â”† spa      â”† Tengo que irme a dormir.        â”‚\n",
              "â”‚ 2     â”† spa      â”† Â¿QuÃ© estÃ¡s haciendo?            â”‚\n",
              "â”‚ 3     â”† spa      â”† Â¿QuÃ© es eso?                    â”‚\n",
              "â”‚ 4     â”† spa      â”† Â¡Hoy es 18 de junio y es el cuâ€¦ â”‚\n",
              "â”‚ 5     â”† spa      â”† Â¡Feliz cumpleaÃ±os, Muiriel!     â”‚\n",
              "â”‚ 6     â”† spa      â”† Ahora, Muiriel tiene 20 aÃ±os.   â”‚\n",
              "â”‚ 7     â”† spa      â”† La contraseÃ±a es \"Muiriel\".     â”‚\n",
              "â”‚ 8     â”† spa      â”† VolverÃ© pronto.                 â”‚\n",
              "â”‚ 9     â”† spa      â”† No tengo palabras.              â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (10, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>language</th><th>text</th></tr><tr><td>u32</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>&quot;spa&quot;</td><td>&quot;Â¡Intentemos algo!&quot;</td></tr><tr><td>1</td><td>&quot;spa&quot;</td><td>&quot;Tengo que irme a dormir.&quot;</td></tr><tr><td>2</td><td>&quot;spa&quot;</td><td>&quot;Â¿QuÃ© estÃ¡s haciendo?&quot;</td></tr><tr><td>3</td><td>&quot;spa&quot;</td><td>&quot;Â¿QuÃ© es eso?&quot;</td></tr><tr><td>4</td><td>&quot;spa&quot;</td><td>&quot;Â¡Hoy es 18 de junio y es el cuâ€¦</td></tr><tr><td>5</td><td>&quot;spa&quot;</td><td>&quot;Â¡Feliz cumpleaÃ±os, Muiriel!&quot;</td></tr><tr><td>6</td><td>&quot;spa&quot;</td><td>&quot;Ahora, Muiriel tiene 20 aÃ±os.&quot;</td></tr><tr><td>7</td><td>&quot;spa&quot;</td><td>&quot;La contraseÃ±a es &quot;Muiriel&quot;.&quot;</td></tr><tr><td>8</td><td>&quot;spa&quot;</td><td>&quot;VolverÃ© pronto.&quot;</td></tr><tr><td>9</td><td>&quot;spa&quot;</td><td>&quot;No tengo palabras.&quot;</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.height"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKpEYAVHqHF5",
        "outputId": "6d0e2441-79a4-4c61-cc89-f5d9f954d6db"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6854075"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Preprocess"
      ],
      "metadata": {
        "id": "TZN03VKgqSoK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean garbage characters"
      ],
      "metadata": {
        "id": "5oXStXg5sEq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(dataframe):\n",
        "    chars_to_replace = [\"ï¼\", \"ï¼Ÿ\", \"ï½¡\", \"ã€‚\", \"ï¼‚\", \"ï¼ƒ\", \"ï¼„\", \"ï¼…\", \"ï¼†\", \"ï¼‡\",\n",
        "                        \"ï¼ˆ\", \"ï¼‰\", \"ï¼Š\", \"ï¼‹\", \"ï¼Œ\", \"ï¼\", \"ï¼\", \"ï¼š\", \"ï¼›\", \"ï¼œ\",\n",
        "                        \"ï¼\", \"ï¼\", \"ï¼ \", \"ï¼»\", \"ï¼¼\", \"ï¼½\", \"ï¼¾\", \"ï¼¿\", \"ï½€\", \"ï½›\",\n",
        "                        \"ï½œ\", \"ï½\", \"ï½\", \"ï½Ÿ\", \"ï½ \", \"ï½¢\", \"ï½£\", \"ï½¤\", \"ã€\", \"ã€ƒ\",\n",
        "                        \"ã€‹\", \"ã€Œ\", \"ã€\", \"ã€\", \"ã€\", \"ã€\", \"ã€‘\", \"ã€”\", \"ã€•\", \"ã€–\",\n",
        "                        \"ã€—\", \"ã€˜\", \"ã€™\", \"ã€š\", \"ã€›\", \"ã€œ\", \"ã€\", \"ã€\", \"ã€Ÿ\", \"ã€°\",\n",
        "                        \"ã€¾\", \"ã€¿\", \"â€“\", \"â€”\", \"â€˜\", \"â€™\", \"â€›\", \"â€œ\", \"â€\", \"â€\", \"â€Ÿ\",\n",
        "                        \"â€¦\", \"â€§\", \"ï¹\", \".\", \",\", \"(\", \")\", \"{\", \"}\", \"[\", \"]\",\n",
        "                        \"!\", \"@\", \"#\", \"$\", \"%\", \"^\", \"&\", \"*\", \"?\", \"_\", \"-\",\n",
        "                        \"+\", \"=\", \"/\", \"`\", \"~\", \"'\", \";\", \":\", \"]\", \"Â¡\", \"\\\"\",\n",
        "                        \"<\", \">\", \"â‚¬\", \"ğ‘\", \"Ï€\", \"â„–\", \"â€•\", \"Ì€\", \"Ì\", \"Ã—\", \"Å“\", \"Å’\",\n",
        "                        \"Å­\", \"É›\", \"É£\", \"Ğ°\", \"á¸\", \"á¸¥\", \"á¹›\", \"áº“\", \"áˆ˜\", \"áˆ€\", \"áˆˆ\",\n",
        "                        \"áˆ\", \"áˆ\", \"áˆ­\", \"áˆ°\", \"á‰ \", \"á‰¥\", \"á‰µ\", \"áŠ’\", \"áŠ•\", \"áŠ \", \"áŠ¥\",\n",
        "                        \"áŠ«\", \"áŠ­\", \"á‹­\", \"á¢\", \"Ù±\", \"Ù°\", \"Ù’\", \"Ù\", \"Â«\", \"Â»\", \"Â°\", \"Â¹\",\n",
        "                        \"Â²\", \"Â³\", \"Â´\", \"Â§\", \"Â½\", \"âˆš\", \"âˆ’\", \"â„\", \"ğ‘˜\", \"ğ‘¥\", \"â‚„\",\n",
        "                        \"â‚‚\", \"â°\", \"â€º\", \"â€¹\", \"â€²\", \"Â¿\", \"Âº\", \"ã¾\", \"Â£\", \"Â¥\", \"ã‹\",\n",
        "                        \"ã®\", \"â‚º\", \"Ùª\", \"ØŸ\", \"Ø›\", \"Ñ£\" ]\n",
        "    pattern = \"[\" + re.escape(\"\".join(chars_to_replace)) + \"]\"\n",
        "\n",
        "    dataframe = dataframe.with_columns(\n",
        "        pl.col(\"text\")\n",
        "        .str.replace_all(pattern, \" \")  # Remove special characters\n",
        "        .str.replace_all(r\"\\d\", \" \")    # Remove digits\n",
        "        .str.replace_all(r\"\\s+\", \" \")   # Replace multiple whitespace with single space\n",
        "        .str.strip_chars()              # Remove leading/trailing whitespace\n",
        "    )\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "HkPUrclRQV0p"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data = clean_text(data)"
      ],
      "metadata": {
        "id": "zbqxpQSJQelk"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Split Train set and Validation set"
      ],
      "metadata": {
        "id": "Lpbr4JIitkN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_validation_split_by_language(data, samples_per_language=100):\n",
        "    validation_set = (\n",
        "        data\n",
        "        .group_by(\"language\")\n",
        "        .map_groups(lambda group:\n",
        "            group.sample(n=min(samples_per_language, len(group))))\n",
        "    )\n",
        "\n",
        "    training_set = data.join(\n",
        "        validation_set.select(\"index\"),\n",
        "        on=\"index\",\n",
        "        how=\"anti\"\n",
        "    )\n",
        "\n",
        "    if \"index\" in training_set.columns:\n",
        "        training_set = training_set.drop(\"index\")\n",
        "    training_set = training_set.with_row_index(name=\"index\", offset=0)\n",
        "\n",
        "    if \"index\" in validation_set.columns:\n",
        "        validation_set = validation_set.drop(\"index\")\n",
        "    validation_set = validation_set.with_row_index(name=\"index\", offset=0)\n",
        "\n",
        "    return training_set, validation_set"
      ],
      "metadata": {
        "id": "4hf8DHAN8EDk"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "training_set, validation_set = train_validation_split_by_language(cleaned_data)"
      ],
      "metadata": {
        "id": "BN7qXkDO8aRu"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training data shape: {training_set.shape}\")\n",
        "print(f\"Validation data shape: {validation_set.shape}\")\n",
        "print(\"\\nValidation samples per language:\")\n",
        "print(validation_set[\"language\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWHE0PhytzCG",
        "outputId": "7e237e6a-788d-449f-fd33-aa503e76dd3c"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (6853075, 3)\n",
            "Validation data shape: (1000, 3)\n",
            "\n",
            "Validation samples per language:\n",
            "shape: (10, 2)\n",
            "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”\n",
            "â”‚ language â”† count â”‚\n",
            "â”‚ ---      â”† ---   â”‚\n",
            "â”‚ str      â”† u32   â”‚\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\n",
            "â”‚ eng      â”† 100   â”‚\n",
            "â”‚ ita      â”† 100   â”‚\n",
            "â”‚ pes      â”† 100   â”‚\n",
            "â”‚ deu      â”† 100   â”‚\n",
            "â”‚ tur      â”† 100   â”‚\n",
            "â”‚ spa      â”† 100   â”‚\n",
            "â”‚ ara      â”† 100   â”‚\n",
            "â”‚ fra      â”† 100   â”‚\n",
            "â”‚ nld      â”† 100   â”‚\n",
            "â”‚ rus      â”† 100   â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Filter all Language chracters"
      ],
      "metadata": {
        "id": "JpOPG0bQ8rs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_language_chars_dictionary(\n",
        "    data: pl.DataFrame,\n",
        "    cutoff_thresholds: Dict[str, int] = None,\n",
        "    default_cutoff: int = 10\n",
        ") -> Tuple[Dict[str, Set[str]], Dict[str, Dict[str, int]]]:\n",
        "\n",
        "    languages = data[\"language\"].unique().to_list()\n",
        "    char_frequencies = {lang: Counter() for lang in languages}\n",
        "    language_chars = {lang: set() for lang in languages}\n",
        "\n",
        "    for language, text in data.select([\"language\", \"text\"]).iter_rows():\n",
        "        char_frequencies[language].update(text)\n",
        "\n",
        "    for lang in languages:\n",
        "        threshold = cutoff_thresholds.get(lang, default_cutoff)\n",
        "        language_chars[lang] = {\n",
        "            char for char, count in char_frequencies[lang].items()\n",
        "            if count >= threshold\n",
        "        }\n",
        "\n",
        "    return language_chars, char_frequencies"
      ],
      "metadata": {
        "id": "kOTXUiRVBg5r"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cutoff_thresholds = {\n",
        "    \"ara\": 100,\n",
        "    \"nld\": 100,\n",
        "    \"eng\": 100,\n",
        "    \"ita\": 100,\n",
        "    \"fra\": 100,\n",
        "    \"deu\": 100,\n",
        "    \"pes\": 100,\n",
        "    \"rus\": 100,\n",
        "    \"spa\": 100,\n",
        "    \"tur\": 100\n",
        "}\n",
        "\n",
        "language_chars, char_frequencies = create_language_chars_dictionary(training_set, cutoff_thresholds=cutoff_thresholds, default_cutoff=100)\n",
        "\n",
        "for lang, chars in language_chars.items():\n",
        "    threshold = cutoff_thresholds.get(lang, 100)\n",
        "    print(f\"\\nLanguage: {lang} (cutoff: {threshold})\")\n",
        "    print(f\"Total unique chars: {len(char_frequencies[lang])}\")\n",
        "    print(f\"Filtered chars count: {len(chars)}\")\n",
        "    print(\"Sample frequent chars:\", sorted(list(chars))[:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zG03PeWCCbm",
        "outputId": "7ccbc761-12f3-406f-b2f5-eb7ee6729dae"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Language: deu (cutoff: 100)\n",
            "Total unique chars: 335\n",
            "Filtered chars count: 64\n",
            "Sample frequent chars: [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xad', 'Ã„', 'Ã–', 'Ãœ', 'ÃŸ', 'Ã¤', 'Ã©', 'Ã¶', 'Ã¼', 'Å', 'â€š']\n",
            "\n",
            "Language: ara (cutoff: 100)\n",
            "Total unique chars: 183\n",
            "Filtered chars count: 45\n",
            "Sample frequent chars: [' ', 'ØŒ', 'Ø¡', 'Ø¢', 'Ø£', 'Ø¤', 'Ø¥', 'Ø¦', 'Ø§', 'Ø¨', 'Ø©', 'Øª', 'Ø«', 'Ø¬', 'Ø­', 'Ø®', 'Ø¯', 'Ø°', 'Ø±', 'Ø²', 'Ø³', 'Ø´', 'Øµ', 'Ø¶', 'Ø·', 'Ø¸', 'Ø¹', 'Øº', 'Ù', 'Ù‚', 'Ùƒ', 'Ù„', 'Ù…', 'Ù†', 'Ù‡', 'Ùˆ', 'Ù‰', 'ÙŠ', 'Ù‹', 'ÙŒ', 'Ù', 'Ù', 'Ù', 'Ù‘', 'ÛŒ']\n",
            "\n",
            "Language: tur (cutoff: 100)\n",
            "Total unique chars: 180\n",
            "Filtered chars count: 65\n",
            "Sample frequent chars: [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Ã‡', 'Ã–', 'Ãœ', 'Ã¢', 'Ã§', 'Ã®', 'Ã¶', 'Ã»', 'Ã¼', 'ÄŸ', 'Ä°', 'Ä±', 'Å', 'ÅŸ', '\\u200b']\n",
            "\n",
            "Language: pes (cutoff: 100)\n",
            "Total unique chars: 126\n",
            "Filtered chars count: 45\n",
            "Sample frequent chars: [' ', 'ØŒ', 'Ø¡', 'Ø¢', 'Ø£', 'Ø¤', 'Ø¦', 'Ø§', 'Ø¨', 'Øª', 'Ø«', 'Ø¬', 'Ø­', 'Ø®', 'Ø¯', 'Ø°', 'Ø±', 'Ø²', 'Ø³', 'Ø´', 'Øµ', 'Ø¶', 'Ø·', 'Ø¸', 'Ø¹', 'Øº', 'Ù', 'Ù‚', 'Ùƒ', 'Ù„', 'Ù…', 'Ù†', 'Ù‡', 'Ùˆ', 'ÙŠ', 'Ù‹', 'Ù', 'Ù”', 'Ù¾', 'Ú†', 'Ú˜', 'Ú©', 'Ú¯', 'ÛŒ', '\\u200c']\n",
            "\n",
            "Language: rus (cutoff: 100)\n",
            "Total unique chars: 232\n",
            "Filtered chars count: 98\n",
            "Sample frequent chars: [' ', 'A', 'B', 'C', 'D', 'F', 'I', 'L', 'M', 'P', 'S', 'T', 'V', 'W', 'X', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'w', 'x', 'y', 'Ğ', 'Ğ‘', 'Ğ’', 'Ğ“', 'Ğ”', 'Ğ•', 'Ğ–', 'Ğ—', 'Ğ˜', 'Ğ™', 'Ğš', 'Ğ›', 'Ğœ', 'Ğ', 'Ğ', 'ĞŸ', 'Ğ ', 'Ğ¡', 'Ğ¢', 'Ğ£', 'Ğ¤', 'Ğ¥', 'Ğ¦', 'Ğ§', 'Ğ¨', 'Ğ­', 'Ğ®', 'Ğ¯', 'Ğ±', 'Ğ²', 'Ğ³', 'Ğ´', 'Ğµ', 'Ğ¶', 'Ğ·', 'Ğ¸', 'Ğ¹', 'Ğº', 'Ğ»', 'Ğ¼', 'Ğ½', 'Ğ¾', 'Ğ¿', 'Ñ€', 'Ñ', 'Ñ‚', 'Ñƒ', 'Ñ„', 'Ñ…', 'Ñ†', 'Ñ‡', 'Ñˆ', 'Ñ‰', 'ÑŠ', 'Ñ‹', 'ÑŒ', 'Ñ', 'Ñ', 'Ñ', 'Ñ‘', '\\u200b']\n",
            "\n",
            "Language: fra (cutoff: 100)\n",
            "Total unique chars: 221\n",
            "Filtered chars count: 70\n",
            "Sample frequent chars: [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Ã€', 'Ã‡', 'Ã‰', 'ÃŠ', 'Ã”', 'Ã ', 'Ã¢', 'Ã§', 'Ã¨', 'Ã©', 'Ãª', 'Ã«', 'Ã®', 'Ã¯', 'Ã´', 'Ã¹', 'Ã»']\n",
            "\n",
            "Language: nld (cutoff: 100)\n",
            "Total unique chars: 140\n",
            "Filtered chars count: 57\n",
            "Sample frequent chars: [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Ã¨', 'Ã©', 'Ã«', 'Ã¯', 'Ã¼', '\\u200b']\n",
            "\n",
            "Language: eng (cutoff: 100)\n",
            "Total unique chars: 415\n",
            "Filtered chars count: 56\n",
            "Sample frequent chars: [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Ã¡', 'Ã©', 'Ã­']\n",
            "\n",
            "Language: spa (cutoff: 100)\n",
            "Total unique chars: 187\n",
            "Filtered chars count: 63\n",
            "Sample frequent chars: [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Ã', 'Ã‰', 'Ãš', 'Ã¡', 'Ã©', 'Ã­', 'Ã±', 'Ã³', 'Ãº', 'Ã¼']\n",
            "\n",
            "Language: ita (cutoff: 100)\n",
            "Total unique chars: 159\n",
            "Filtered chars count: 60\n",
            "Sample frequent chars: [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Ãˆ', 'Ã ', 'Ã¨', 'Ã©', 'Ã¬', 'Ã²', 'Ã¹']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 10: Predict Language by chars"
      ],
      "metadata": {
        "id": "1wBGxrIpNDf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_language_by_chars(validation_set: pl.DataFrame, language_chars: dict[str, set[str]]) -> pl.DataFrame:\n",
        "    lang_char_sets = {lang: set(chars) for lang, chars in language_chars.items()}\n",
        "    languages = list(lang_char_sets.keys())\n",
        "\n",
        "    text_chars_list = validation_set[\"text\"].to_list()\n",
        "    predictions = []\n",
        "\n",
        "    for text in text_chars_list:\n",
        "        text_chars = set(text)\n",
        "        best_lang = max(\n",
        "            languages,\n",
        "            key=lambda lang: len(text_chars & lang_char_sets[lang])\n",
        "        )\n",
        "        predictions.append(best_lang)\n",
        "\n",
        "    return validation_set.with_columns(\n",
        "        predicted_language=pl.Series(predictions)\n",
        "    )"
      ],
      "metadata": {
        "id": "nk9ec2TANE9h"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_set = predict_language_by_chars(validation_set, language_chars)"
      ],
      "metadata": {
        "id": "368hoUIYVE4Y"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_set.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "rf2qeYuZVVjp",
        "outputId": "a63ce8ac-a3b4-4789-b4cb-d9db6bc22628"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (10, 4)\n",
              "â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
              "â”‚ index â”† language â”† text                            â”† predicted_language â”‚\n",
              "â”‚ ---   â”† ---      â”† ---                             â”† ---                â”‚\n",
              "â”‚ u32   â”† str      â”† str                             â”† str                â”‚\n",
              "â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
              "â”‚ 0     â”† tur      â”† O kadar da komik deÄŸildi        â”† tur                â”‚\n",
              "â”‚ 1     â”† tur      â”† Avustralya da konuÅŸulan dil Ä°nâ€¦ â”† tur                â”‚\n",
              "â”‚ 2     â”† tur      â”† Bu fotoÄŸrafÄ± gÃ¶rÃ¼nce ailemi dÃ¼â€¦ â”† tur                â”‚\n",
              "â”‚ 3     â”† tur      â”† Burada Ä°spanyolca konuÅŸulur     â”† tur                â”‚\n",
              "â”‚ 4     â”† tur      â”† Dinsiz piskoposun yorumuyla alâ€¦ â”† deu                â”‚\n",
              "â”‚ 5     â”† tur      â”† Ãœye misiniz                     â”† deu                â”‚\n",
              "â”‚ 6     â”† tur      â”† Yayan gittim                    â”† deu                â”‚\n",
              "â”‚ 7     â”† tur      â”† Bilim hakkÄ±nda daha fazla bilmâ€¦ â”† tur                â”‚\n",
              "â”‚ 8     â”† tur      â”† AltÄ±n gÃ¼mÃ¼ÅŸten daha aÄŸÄ±rdÄ±r     â”† tur                â”‚\n",
              "â”‚ 9     â”† tur      â”† Tom Mary ile konuÅŸuyor          â”† tur                â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (10, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>language</th><th>text</th><th>predicted_language</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>&quot;tur&quot;</td><td>&quot;O kadar da komik deÄŸildi&quot;</td><td>&quot;tur&quot;</td></tr><tr><td>1</td><td>&quot;tur&quot;</td><td>&quot;Avustralya da konuÅŸulan dil Ä°nâ€¦</td><td>&quot;tur&quot;</td></tr><tr><td>2</td><td>&quot;tur&quot;</td><td>&quot;Bu fotoÄŸrafÄ± gÃ¶rÃ¼nce ailemi dÃ¼â€¦</td><td>&quot;tur&quot;</td></tr><tr><td>3</td><td>&quot;tur&quot;</td><td>&quot;Burada Ä°spanyolca konuÅŸulur&quot;</td><td>&quot;tur&quot;</td></tr><tr><td>4</td><td>&quot;tur&quot;</td><td>&quot;Dinsiz piskoposun yorumuyla alâ€¦</td><td>&quot;deu&quot;</td></tr><tr><td>5</td><td>&quot;tur&quot;</td><td>&quot;Ãœye misiniz&quot;</td><td>&quot;deu&quot;</td></tr><tr><td>6</td><td>&quot;tur&quot;</td><td>&quot;Yayan gittim&quot;</td><td>&quot;deu&quot;</td></tr><tr><td>7</td><td>&quot;tur&quot;</td><td>&quot;Bilim hakkÄ±nda daha fazla bilmâ€¦</td><td>&quot;tur&quot;</td></tr><tr><td>8</td><td>&quot;tur&quot;</td><td>&quot;AltÄ±n gÃ¼mÃ¼ÅŸten daha aÄŸÄ±rdÄ±r&quot;</td><td>&quot;tur&quot;</td></tr><tr><td>9</td><td>&quot;tur&quot;</td><td>&quot;Tom Mary ile konuÅŸuyor&quot;</td><td>&quot;tur&quot;</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 11: Calculate Detailed Accuracy"
      ],
      "metadata": {
        "id": "1dTXb154WUOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_detailed_accuracy(df: pl.DataFrame) -> dict:\n",
        "    confusion_counts = (\n",
        "        df\n",
        "        .group_by(\"language\", \"predicted_language\")\n",
        "        .agg(pl.len().alias(\"n\"))\n",
        "        .sort(\"language\", \"predicted_language\")\n",
        "    )\n",
        "\n",
        "    class_acc = (\n",
        "        df\n",
        "        .group_by(\"language\")\n",
        "        .agg(\n",
        "            (pl.col(\"language\") == pl.col(\"predicted_language\"))\n",
        "            .mean()\n",
        "            .alias(\"accuracy\")\n",
        "        )\n",
        "        .sort(\"language\")\n",
        "    )\n",
        "\n",
        "    class_acc_dict = {\n",
        "        row[\"language\"]: row[\"accuracy\"]\n",
        "        for row in class_acc.iter_rows(named=True)\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        \"overall_accuracy\": (df[\"language\"] == df[\"predicted_language\"]).mean(),\n",
        "        \"class_accuracy\": class_acc_dict,\n",
        "        \"confusion_counts\": confusion_counts\n",
        "    }"
      ],
      "metadata": {
        "id": "Mj2qm_JqcflA"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = calculate_detailed_accuracy(validation_set)"
      ],
      "metadata": {
        "id": "sQT9C7pqeWLN"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Overall Accuracy: {metrics['overall_accuracy']:.2%}\")\n",
        "print(\"\\nPer-Class Accuracy:\")\n",
        "for lang, acc in metrics[\"class_accuracy\"].items():\n",
        "    print(f\"{lang}: {acc:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVseXjdieVn9",
        "outputId": "eeea457d-b49b-4458-b7ff-31cd3131c5b1"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy: 52.50%\n",
            "\n",
            "Per-Class Accuracy:\n",
            "ara: 100.00%\n",
            "deu: 100.00%\n",
            "eng: 0.00%\n",
            "fra: 35.00%\n",
            "ita: 3.00%\n",
            "nld: 0.00%\n",
            "pes: 81.00%\n",
            "rus: 100.00%\n",
            "spa: 23.00%\n",
            "tur: 83.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 12:"
      ],
      "metadata": {
        "id": "Z-kXk9eaei1h"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MND_iwVremdH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}